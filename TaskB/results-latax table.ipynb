{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6cfc876-4268-4ca7-b61f-f90d1691fd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mgeonames\u001b[0m/  readme.md  \u001b[01;34mschema\u001b[0m/  \u001b[01;34mumls\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52d1204b-dfa6-41aa-a8a3-ffec8e5867bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-geonames-bert_large.nofinetuning.test.log.txt         \u001b[0m\u001b[01;34mbart_large\u001b[0m/\n",
      "2-geonames-bart_large.nofinetuning.test.log.txt         \u001b[01;34mbert_large\u001b[0m/\n",
      "3-geonames-flan_t5_large.nofinetuning.test.log.txt      \u001b[01;34mbloom_1b7\u001b[0m/\n",
      "4-geonames-flan_t5_xl.nofinetuning.test.log.txt         \u001b[01;34mbloom_3b\u001b[0m/\n",
      "5-geonames-bloom_1b7.nofinetuning.test.log.txt          \u001b[01;34mflan_t5_large\u001b[0m/\n",
      "6-geonames-bloom_3b.nofinetuning.test.log.txt           \u001b[01;34mflan_t5_xl\u001b[0m/\n",
      "7-geonames-gpt3.nofinetuning.test.log.txt               \u001b[01;34mgeonames_flan_t5_large\u001b[0m/\n",
      "8-geonames-geonames_flan_t5_large.fewshot.test.log.txt  \u001b[01;34mgeonames_flan_t5_xl\u001b[0m/\n",
      "9-geonames-geonames_flan_t5_xl.fewshot.test.log.txt     \u001b[01;34mgpt3\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls results/geonames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2ed354f-2fa0-4779-bb8b-2c99c28cf22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET: umls\n",
      "& BERT-Large & 51.59 &  48.89 &  49.63 &  47.66 &  51.84 &  50.85 &  50.61 &  50.36\\\\ \n",
      "& BART-Large & 48.4 &  54.79 &  50.36 &  52.57 &  47.17 &  54.05 &  45.94 &  53.07\\\\ \n",
      "& Flan-T5-Large & 50.12 &  51.35 &  55.77 &  41.76 &  49.63 &  51.1 &  50.36 &  51.84\\\\ \n",
      "& Flan-T5-XL & 64.61 &  50.36 &  52.33 &  43.98 &  62.16 &  45.94 &  52.82 &  41.27\\\\ \n",
      "& BLOOM-1b7 & 50.85 &  51.59 &  50.85 &  52.57 &  50.85 &  51.84 &  49.87 &  50.61\\\\ \n",
      "& BLOOM-3b & 49.63 &  52.08 &  49.63 &  51.59 &  49.63 &  51.84 &  49.38 &  52.57\\\\ \n",
      "& GPT3 & 53.31 &  49.87 &  51.1 &  44.22 &  52.57 &  47.66 &  46.19 &  47.66\\\\ \n",
      "------------------------------------------------------------\n",
      "DATASET: geonames\n",
      "& BERT-Large & 41.54 &  56.25 &  42.64 &  53.3 &  44.39 &  52.11 &  45.03 &  55.05\\\\ \n",
      "& BART-Large & 45.86 &  50.45 &  44.02 &  52.75 &  41.91 &  51.37 &  36.94 &  57.81\\\\ \n",
      "& Flan-T5-Large & 59.74 &  48.8 &  54.13 &  48.25 &  45.03 &  51.74 &  47.33 &  43.38\\\\ \n",
      "& Flan-T5-XL & 49.63 &  45.58 &  48.52 &  54.13 &  44.02 &  48.16 &  50.55 &  44.3\\\\ \n",
      "& BLOOM-1b7 & 49.63 &  37.31 &  49.63 &  48.89 &  49.9 &  47.79 &  50.64 &  49.08\\\\ \n",
      "& BLOOM-3b & 50.73 &  46.04 &  56.43 &  40.62 &  50.27 &  49.54 &  56.15 &  45.12\\\\ \n",
      "& GPT3 & 46.32 &  52.38 &  44.48 &  55.42 &  48.06 &  54.04 &  46.32 &  53.67\\\\ \n",
      "------------------------------------------------------------\n",
      "DATASET: schema\n",
      "& BERT-Large & 48.8 &  49.78 &  49.71 &  48.92 &  50.51 &  49.39 &  49.83 &  49.6\\\\ \n",
      "& BART-Large & 48.36 &  49.08 &  49.22 &  53.06 &  47.63 &  50.25 &  47.05 &  52.03\\\\ \n",
      "& Flan-T5-Large & 48.54 &  56.15 &  50.7 &  57.67 &  40.73 &  59.05 &  43.42 &  51.89\\\\ \n",
      "& Flan-T5-XL & 52.22 &  49.81 &  50.02 &  51.63 &  48.87 &  50.11 &  49.83 &  50.88\\\\ \n",
      "& BLOOM-1b7 & 49.95 &  53.06 &  49.95 &  50.91 &  49.67 &  53.04 &  50.44 &  50.98\\\\ \n",
      "& BLOOM-3b & 50.32 &  48.01 &  51.4 &  50.11 &  49.78 &  51.24 &  52.27 &  49.01\\\\ \n",
      "& GPT3 & 50.42 &  49.29 &  51.24 &  48.43 &  48.52 &  49.6 &  49.01 &  49.76\\\\ \n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datahandler import DataReader\n",
    "\n",
    "results_dir = \"results\"\n",
    "templates = [f\"-{str(index)}-\" for index in range(8)]\n",
    "models = [\"bert_large\", \"bart_large\", \"flan_t5_large\", \"flan_t5_xl\", \"bloom_1b7\", \"bloom_3b\", \"gpt3\"]\n",
    "models_dict = {\"bert_large\":\"BERT-Large\", \"bart_large\":\"BART-Large\", \"flan_t5_large\":\"Flan-T5-Large\", \"flan_t5_xl\":\"Flan-T5-XL\", \n",
    "               \"bloom_1b7\":\"BLOOM-1b7\", \"bloom_3b\":\"BLOOM-3b\", \"gpt3\":\"GPT3\"}\n",
    "\n",
    "for dataset in os.listdir(results_dir): # geonames, wn18rr, nci, snomedct, medcin\n",
    "    if \".\" in dataset:# or \"geonames\" in dataset:\n",
    "        continue\n",
    "    print(\"DATASET:\", dataset)\n",
    "    dataset_path = os.path.join(results_dir, dataset)\n",
    "    for model in models:  \n",
    "        # print(model)\n",
    "        # if model == \"bloom_3b\" and dataset == \"geonames\":\n",
    "        #     continue\n",
    "        model_results_dir = os.path.join(dataset_path, model)\n",
    "        print(\"&\",models_dict[model], end=\" & \")\n",
    "        for template in templates: # template-1, template-2, .... , template-8\n",
    "            for report_files in os.listdir(model_results_dir):\n",
    "                if \"report\" in report_files and template in report_files:\n",
    "                    template_report_file_path = os.path.join(model_results_dir, report_files)\n",
    "                    report = DataReader.load_json(template_report_file_path)\n",
    "                    # print(dict(report['results']['clf-report']))\n",
    "                    if template == \"-7-\":\n",
    "                        print(int(str(report['results']['accuracy'])[2:6])/100, end='\\\\\\ \\n')\n",
    "                    else:\n",
    "                        print(int(str(report['results']['accuracy'])[2:6])/100, end=' &  ')\n",
    "                    # print(template_report_file_path)\n",
    "    print(\"--\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b7a8e6a-3227-499f-92d1-39322e75cd46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET: umls\n",
      "BERT-Large<br>BART-Large<br>Flan-T5-Large<br>Flan-T5-XL<br>BLOOM-1b7<br>BLOOM-3b<br>GPT3<br>\n",
      "\n",
      "& BERT-Large & 48.21 &  38.84 &  41.46 &  40.41 &  45.88 &  40.91 &  41.04 &  42.92\\\\ \n",
      "& BART-Large & 36.02 &  48.21 &  41.42 &  49.9 &  39.37 &  47.47 &  42.39 &  45.46\\\\ \n",
      "& Flan-T5-Large & 47.55 &  51.22 &  55.32 &  40.94 &  49.45 &  50.87 &  44.23 &  42.9\\\\ \n",
      "& Flan-T5-XL & 64.25 &  46.53 &  51.0 &  41.54 &  60.07 &  42.83 &  51.25 &  41.18\\\\ \n",
      "& BLOOM-1b7 & 33.71 &  36.18 &  33.71 &  38.26 &  33.71 &  35.89 &  33.27 &  33.6\\\\ \n",
      "& BLOOM-3b & 33.16 &  37.23 &  34.82 &  35.77 &  33.16 &  35.89 &  33.05 &  37.48\\\\ \n",
      "& GPT3 & 51.58 &  49.41 &  49.86 &  42.9 &  50.57 &  46.07 &  45.36 &  46.72\\\\ \n",
      "\n",
      "48.21<br>  36.02<br>  47.55<br>  64.25<br>  33.71<br>  33.16<br>  51.58 |38.84<br>  48.21<br>  51.22<br>  46.53<br>  36.18<br>  37.23<br>  49.41 |41.46<br>  41.42<br>  55.32<br>  51.0<br>  33.71<br>  34.82<br>  49.86 |40.41<br>  49.9<br>  40.94<br>  41.54<br>  38.26<br>  35.77<br>  42.9 |45.88<br>  39.37<br>  49.45<br>  60.07<br>  33.71<br>  33.16<br>  50.57 |40.91<br>  47.47<br>  50.87<br>  42.83<br>  35.89<br>  35.89<br>  46.07 |41.04<br>  42.39<br>  44.23<br>  51.25<br>  33.27<br>  33.05<br>  45.36 |42.92<br>  45.46<br>  42.9<br>  41.18<br>  33.6<br>  37.48<br>  46.72 |\n",
      "------------------------------------------------------------\n",
      "DATASET: geonames\n",
      "BERT-Large<br>BART-Large<br>Flan-T5-Large<br>Flan-T5-XL<br>BLOOM-1b7<br>BLOOM-3b<br>GPT3<br>\n",
      "\n",
      "& BERT-Large & 41.0 &  51.69 &  40.55 &  48.7 &  37.16 &  41.07 &  41.7 &  54.54\\\\ \n",
      "& BART-Large & 38.11 &  41.03 &  40.55 &  52.5 &  39.09 &  45.8 &  36.67 &  55.4\\\\ \n",
      "& Flan-T5-Large & 59.63 &  48.24 &  54.08 &  48.24 &  44.4 &  51.3 &  36.4 &  38.44\\\\ \n",
      "& Flan-T5-XL & 49.37 &  44.05 &  45.09 &  52.41 &  43.92 &  46.34 &  49.98 &  44.29\\\\ \n",
      "& BLOOM-1b7 & 33.16 &  31.04 &  33.16 &  32.83 &  33.77 &  33.53 &  36.67 &  32.92\\\\ \n",
      "& BLOOM-3b & 35.85 &  39.12 &  53.92 &  30.22 &  35.62 &  33.6 &  48.26 &  37.73\\\\ \n",
      "& GPT3 & 43.43 &  51.74 &  42.7 &  53.2 &  46.04 &  52.56 &  45.49 &  52.62\\\\ \n",
      "\n",
      "41.0<br>  38.11<br>  59.63<br>  49.37<br>  33.16<br>  35.85<br>  43.43 |51.69<br>  41.03<br>  48.24<br>  44.05<br>  31.04<br>  39.12<br>  51.74 |40.55<br>  40.55<br>  54.08<br>  45.09<br>  33.16<br>  53.92<br>  42.7 |48.7<br>  52.5<br>  48.24<br>  52.41<br>  32.83<br>  30.22<br>  53.2 |37.16<br>  39.09<br>  44.4<br>  43.92<br>  33.77<br>  35.62<br>  46.04 |41.07<br>  45.8<br>  51.3<br>  46.34<br>  33.53<br>  33.6<br>  52.56 |41.7<br>  36.67<br>  36.4<br>  49.98<br>  36.67<br>  48.26<br>  45.49 |54.54<br>  55.4<br>  38.44<br>  44.29<br>  32.92<br>  37.73<br>  52.62 |\n",
      "------------------------------------------------------------\n",
      "DATASET: schema\n",
      "BERT-Large<br>BART-Large<br>Flan-T5-Large<br>Flan-T5-XL<br>BLOOM-1b7<br>BLOOM-3b<br>GPT3<br>\n",
      "\n",
      "& BERT-Large & 43.85 &  41.17 &  44.06 &  43.2 &  43.7 &  40.05 &  42.15 &  43.72\\\\ \n",
      "& BART-Large & 34.62 &  38.69 &  39.28 &  52.9 &  38.2 &  41.17 &  43.26 &  42.74\\\\ \n",
      "& Flan-T5-Large & 46.98 &  49.92 &  46.11 &  54.78 &  40.27 &  54.47 &  42.06 &  47.93\\\\ \n",
      "& Flan-T5-XL & 42.7 &  33.45 &  33.59 &  42.76 &  36.69 &  34.04 &  33.75 &  36.45\\\\ \n",
      "& BLOOM-1b7 & 33.39 &  47.83 &  33.39 &  39.77 &  38.92 &  48.56 &  44.35 &  39.57\\\\ \n",
      "& BLOOM-3b & 41.64 &  47.16 &  47.98 &  45.25 &  39.73 &  40.75 &  51.28 &  48.73\\\\ \n",
      "& GPT3 & 49.64 &  49.28 &  50.97 &  48.03 &  47.19 &  48.63 &  48.87 &  49.48\\\\ \n",
      "\n",
      "43.85<br>  34.62<br>  46.98<br>  42.7<br>  33.39<br>  41.64<br>  49.64 |41.17<br>  38.69<br>  49.92<br>  33.45<br>  47.83<br>  47.16<br>  49.28 |44.06<br>  39.28<br>  46.11<br>  33.59<br>  33.39<br>  47.98<br>  50.97 |43.2<br>  52.9<br>  54.78<br>  42.76<br>  39.77<br>  45.25<br>  48.03 |43.7<br>  38.2<br>  40.27<br>  36.69<br>  38.92<br>  39.73<br>  47.19 |40.05<br>  41.17<br>  54.47<br>  34.04<br>  48.56<br>  40.75<br>  48.63 |42.15<br>  43.26<br>  42.06<br>  33.75<br>  44.35<br>  51.28<br>  48.87 |43.72<br>  42.74<br>  47.93<br>  36.45<br>  39.57<br>  48.73<br>  49.48 |\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datahandler import DataReader\n",
    "\n",
    "results_dir = \"results\"\n",
    "templates = [f\"-{str(index)}-\" for index in range(8)]\n",
    "models = [\"bert_large\", \"bart_large\", \"flan_t5_large\", \"flan_t5_xl\", \"bloom_1b7\", \"bloom_3b\", \"gpt3\"]\n",
    "models_dict = {\"bert_large\":\"BERT-Large\", \"bart_large\":\"BART-Large\", \"flan_t5_large\":\"Flan-T5-Large\", \"flan_t5_xl\":\"Flan-T5-XL\", \n",
    "               \"bloom_1b7\":\"BLOOM-1b7\", \"bloom_3b\":\"BLOOM-3b\", \"gpt3\":\"GPT3\"}\n",
    "\n",
    "for dataset in os.listdir(results_dir): # geonames, wn18rr, nci, snomedct, medcin\n",
    "    if \".\" in dataset:# or \"geonames\" in dataset:\n",
    "        continue\n",
    "    print(\"DATASET:\", dataset)\n",
    "    dataset_path = os.path.join(results_dir, dataset)\n",
    "    for model in models:  \n",
    "        print(models_dict[model], end=\"<br>\")\n",
    "    print()\n",
    "    print()\n",
    "    results_dict = {model:{} for model in models}\n",
    "    for model in models:  \n",
    "        model_results_dir = os.path.join(dataset_path, model)\n",
    "        print(\"&\",models_dict[model], end=\" & \")\n",
    "        for template in templates: # template-1, template-2, .... , template-8\n",
    "            for report_files in os.listdir(model_results_dir):\n",
    "                if \"report\" in report_files and template in report_files:\n",
    "                    template_report_file_path = os.path.join(model_results_dir, report_files)\n",
    "                    report = DataReader.load_json(template_report_file_path)\n",
    "                    result = int(str(report['results']['clf-report-dict']['macro avg']['f1-score'])[2:6])/100\n",
    "                    results_dict[model][template] = result\n",
    "                    # print(dict(report['results']['clf-report']))\n",
    "                    if template == \"-7-\":\n",
    "                        print(int(str(report['results']['clf-report-dict']['macro avg']['f1-score'])[2:6])/100, end='\\\\\\ \\n')\n",
    "                        \n",
    "                    else:\n",
    "                        print(int(str(report['results']['clf-report-dict']['macro avg']['f1-score'])[2:6])/100, end=' &  ')\n",
    "                    # print(template_report_file_path)\n",
    "    print()\n",
    "    for template in templates:\n",
    "        for model, templates_scores in results_dict.items():\n",
    "            if model == 'gpt3':\n",
    "                print(templates_scores[template], end=\" \")\n",
    "            else:\n",
    "                print(templates_scores[template], end=\"<br>  \")\n",
    "        print(\"|\", end=\"\")\n",
    "    print()\n",
    "    print(\"--\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fd900a-7e84-43e9-8170-75da3441cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "& GeoNames & 54.54  & 55.4  & \\textbf{59.63}  & 52.41  & 36.67  &  48.26  & 53.2 & & & &\\\\\n",
    "& UMLS     & 48.21  & 49.9  & 55.32   & \\textbf{64.25} &   38.26   &  37.48  & 51.58 & & & &\\\\\n",
    "& Schema   & 44.06  & 52.9  & \\textbf{54.78 }   & 42.70 &   48.56   & 51.28  & 50.97 & - & - & &\\\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91104046-8801-4c3f-9c36-5f69e83aef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from datahandler import DataReader\n",
    "\n",
    "# results_dir = \"results\"\n",
    "# templates = [f\"-{str(index)}-\" for index in range(8)]\n",
    "# models = [\"bert_large\", \"bart_large\", \"flan_t5_large\", \"flan_t5_xl\", \"bloom_1b7\", \"bloom_3b\", \"gpt3\"]\n",
    "# models_dict = {\"bert_large\":\"BERT-Large\", \"bart_large\":\"BART-Large\", \"flan_t5_large\":\"Flan-T5-Large\", \"flan_t5_xl\":\"Flan-T5-XL\", \n",
    "#                \"bloom_1b7\":\"BLOOM-1b7\", \"bloom_3b\":\"BLOOM-3b\", \"gpt3\":\"GPT3\"}\n",
    "\n",
    "# for dataset in os.listdir(results_dir): # geonames, wn18rr, nci, snomedct, medcin\n",
    "#     if \".\" in dataset:# or \"geonames\" in dataset:\n",
    "#         continue\n",
    "#     print(\"DATASET:\", dataset)\n",
    "#     dataset_path = os.path.join(results_dir, dataset)\n",
    "#     results_dict = {model:{} for model in models}\n",
    "#     for model in models:  \n",
    "#         model_results_dir = os.path.join(dataset_path, model)\n",
    "#         print(\"&\",models_dict[model], end=\" & \")\n",
    "#         for template in templates: # template-1, template-2, .... , template-8\n",
    "#             for report_files in os.listdir(model_results_dir):\n",
    "#                 if \"report\" in report_files and template in report_files:\n",
    "#                     template_report_file_path = os.path.join(model_results_dir, report_files)\n",
    "#                     report = DataReader.load_json(template_report_file_path)\n",
    "#                     result = int(str(report['results']['clf-report-dict']['macro avg']['f1-score'])[2:6])/100\n",
    "#                     results_dict[model][template] = result\n",
    "#                     print(\"F1 Score:\", report['results']['clf-report-dict']['macro avg']['f1-score'])\n",
    "#                     # print(template_report_file_path)\n",
    "#         print(\"--\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e817099-b059-4021-b89a-2cd56b7f3a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert accuracy from outputs into f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ecd4b7b-fd77-4e26-9000-eb58f6ca6b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET: schema\n",
      "BERT-Large<br>BART-Large<br>Flan-T5-Large<br>Flan-T5-XL<br>BLOOM-1b7<br>BLOOM-3b<br>GPT3<br>Flan-T5-Large-ours<br>Flan-T5-XL-ours<br>\n",
      "\n",
      "& BERT-Large & 43.85 &  41.17 &  44.06 &  43.2 &  43.7 &  40.05 &  42.15 &  43.72\\\\ \n",
      "& BART-Large & 34.62 &  38.69 &  39.28 &  52.9 &  38.2 &  41.17 &  43.26 &  42.74\\\\ \n",
      "& Flan-T5-Large & 46.98 &  49.92 &  46.11 &  54.78 &  40.27 &  54.47 &  42.06 &  47.93\\\\ \n",
      "& Flan-T5-XL & 42.7 &  33.45 &  33.59 &  42.76 &  36.69 &  34.04 &  33.75 &  36.45\\\\ \n",
      "& BLOOM-1b7 & 33.39 &  47.83 &  33.39 &  39.77 &  38.92 &  48.56 &  44.35 &  39.57\\\\ \n",
      "& BLOOM-3b & 41.64 &  47.16 &  47.98 &  45.25 &  39.73 &  40.75 &  51.28 &  48.73\\\\ \n",
      "& GPT3 & 49.64 &  49.28 &  50.97 &  48.03 &  47.19 &  48.63 &  48.87 &  49.48\\\\ \n",
      "& Flan-T5-Large-ours & 35.35 &  85.43 &  29.82 &  89.24 &  41.3 &  91.68 &  42.46 &  56.39\\\\ \n",
      "& Flan-T5-XL-ours & 91.06 &  57.46 &  74.68 &  65.32 &  91.54 &  50.63 &  91.7 &  33.33\\\\ \n",
      "\n",
      "43.85<br>  34.62<br>  46.98<br>  42.7<br>  33.39<br>  41.64<br>  49.64<br>  35.35<br>  91.06 |41.17<br>  38.69<br>  49.92<br>  33.45<br>  47.83<br>  47.16<br>  49.28<br>  85.43<br>  57.46 |44.06<br>  39.28<br>  46.11<br>  33.59<br>  33.39<br>  47.98<br>  50.97<br>  29.82<br>  74.68 |43.2<br>  52.9<br>  54.78<br>  42.76<br>  39.77<br>  45.25<br>  48.03<br>  89.24<br>  65.32 |43.7<br>  38.2<br>  40.27<br>  36.69<br>  38.92<br>  39.73<br>  47.19<br>  41.3<br>  91.54 |40.05<br>  41.17<br>  54.47<br>  34.04<br>  48.56<br>  40.75<br>  48.63<br>  91.68<br>  50.63 |42.15<br>  43.26<br>  42.06<br>  33.75<br>  44.35<br>  51.28<br>  48.87<br>  42.46<br>  91.7 |43.72<br>  42.74<br>  47.93<br>  36.45<br>  39.57<br>  48.73<br>  49.48<br>  56.39<br>  33.33 |\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datahandler import DataReader\n",
    "\n",
    "results_dir = \"results\"\n",
    "templates = [f\"-{str(index)}-\" for index in range(8)]\n",
    "models = [\"bert_large\", \"bart_large\", \"flan_t5_large\", \"flan_t5_xl\", \"bloom_1b7\", \"bloom_3b\", \"gpt3\", \"schemaorg_flan_t5_large\", \"schemaorg_flan_t5_xl\"]\n",
    "models_dict = {\"bert_large\":\"BERT-Large\", \"bart_large\":\"BART-Large\", \"flan_t5_large\":\"Flan-T5-Large\", \"flan_t5_xl\":\"Flan-T5-XL\", \n",
    "               \"bloom_1b7\":\"BLOOM-1b7\", \"bloom_3b\":\"BLOOM-3b\", \"gpt3\":\"GPT3\", \"schemaorg_flan_t5_large\":\"Flan-T5-Large-ours\", \"schemaorg_flan_t5_xl\":\"Flan-T5-XL-ours\"}\n",
    "\n",
    "dataset='schema'\n",
    "print(\"DATASET:\", dataset)\n",
    "dataset_path = os.path.join(results_dir, dataset)\n",
    "for model in models:  \n",
    "    print(models_dict[model], end=\"<br>\")\n",
    "print()\n",
    "print()\n",
    "results_dict = {model:{} for model in models}\n",
    "for model in models:  \n",
    "    model_results_dir = os.path.join(dataset_path, model)\n",
    "    print(\"&\",models_dict[model], end=\" & \")\n",
    "    for template in templates: # template-1, template-2, .... , template-8\n",
    "        for report_files in os.listdir(model_results_dir):\n",
    "            if \"report\" in report_files and template in report_files:\n",
    "                template_report_file_path = os.path.join(model_results_dir, report_files)\n",
    "                report = DataReader.load_json(template_report_file_path)\n",
    "                result = int(str(report['results']['clf-report-dict']['macro avg']['f1-score'])[2:6])/100\n",
    "                results_dict[model][template] = result\n",
    "                # print(dict(report['results']['clf-report']))\n",
    "                if template == \"-7-\":\n",
    "                    print(int(str(report['results']['clf-report-dict']['macro avg']['f1-score'])[2:6])/100, end='\\\\\\ \\n')\n",
    "\n",
    "                else:\n",
    "                    print(int(str(report['results']['clf-report-dict']['macro avg']['f1-score'])[2:6])/100, end=' &  ')\n",
    "                # print(template_report_file_path)\n",
    "print()\n",
    "for template in templates:\n",
    "    for model, templates_scores in results_dict.items():\n",
    "        if model == 'schemaorg_flan_t5_xl':\n",
    "            print(templates_scores[template], end=\" \")\n",
    "        else:\n",
    "            print(templates_scores[template], end=\"<br>  \")\n",
    "    print(\"|\", end=\"\")\n",
    "print()\n",
    "print(\"--\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbc9e81-e84c-4d89-984f-5ac450f082a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "UMLS   53.42 & 79.25"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
